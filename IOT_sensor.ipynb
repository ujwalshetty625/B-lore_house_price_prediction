{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyOc2s8N+D2aYO8zCpvxRvWx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ujwalshetty625/B-lore_house_price_prediction/blob/main/IOT_sensor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEu2kB29dUys",
        "outputId": "e8d099c8-0dab-4e44-ff64-846569e6fd30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    SampleID  Water_pH  Turbidity_NTU  Chlorine_mg_L BacterialPresence  \\\n",
            "0          1      7.35           0.78           0.82                No   \n",
            "1          2      6.90           0.10           0.68               Yes   \n",
            "2          3      7.45           0.64           1.19               Yes   \n",
            "3          4      8.07           0.18           0.06                No   \n",
            "4          5      6.84           2.48           0.88                No   \n",
            "5          6      6.84           4.43           0.84               Yes   \n",
            "6          7      8.11           0.11           0.21                No   \n",
            "7          8      7.54           4.66           0.80                No   \n",
            "8          9      6.67           1.11           0.60                No   \n",
            "9         10      7.38           0.53           0.43               Yes   \n",
            "10        11      6.68           0.12           0.25               Yes   \n",
            "11        12      6.67           1.04           0.28                No   \n",
            "\n",
            "    EColi_MPN  Rainfall_mm  AvgTemperature_C OutbreakRisk  \n",
            "0           0        18.44              30.3          Low  \n",
            "1           5        30.83              22.4         High  \n",
            "2           2        26.78              32.7         High  \n",
            "3           0        61.65              38.7          Low  \n",
            "4           2        49.33              24.5       Medium  \n",
            "5          10        52.01              21.3         High  \n",
            "6           2        24.55              27.1       Medium  \n",
            "7          50        22.07              26.7       Medium  \n",
            "8           1        41.52              31.3       Medium  \n",
            "9           0        65.23              29.2         High  \n",
            "10        100         9.83              26.5         High  \n",
            "11          1        31.70              28.5       Medium  \n",
            "\n",
            "Dtypes:\n",
            " SampleID               int64\n",
            "Water_pH             float64\n",
            "Turbidity_NTU        float64\n",
            "Chlorine_mg_L        float64\n",
            "BacterialPresence     object\n",
            "EColi_MPN              int64\n",
            "Rainfall_mm          float64\n",
            "AvgTemperature_C     float64\n",
            "OutbreakRisk          object\n",
            "dtype: object\n",
            "\n",
            "Missing values:\n",
            " SampleID             0\n",
            "Water_pH             0\n",
            "Turbidity_NTU        0\n",
            "Chlorine_mg_L        0\n",
            "BacterialPresence    0\n",
            "EColi_MPN            0\n",
            "Rainfall_mm          0\n",
            "AvgTemperature_C     0\n",
            "OutbreakRisk         0\n",
            "dtype: int64\n",
            "\n",
            "OutbreakRisk distribution:\n",
            " OutbreakRisk\n",
            "Medium    995\n",
            "High      762\n",
            "Low       243\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Unique values for EColi_MPN: [np.int64(0), np.int64(1), np.int64(2), np.int64(5), np.int64(10), np.int64(20), np.int64(50), np.int64(100), np.int64(200)]\n",
            "\n",
            "Missing values after numeric coercion:\n",
            " SampleID             0\n",
            "Water_pH             0\n",
            "Turbidity_NTU        0\n",
            "Chlorine_mg_L        0\n",
            "BacterialPresence    0\n",
            "EColi_MPN            0\n",
            "Rainfall_mm          0\n",
            "AvgTemperature_C     0\n",
            "OutbreakRisk         0\n",
            "dtype: int64\n",
            "\n",
            "Feature engineering completed. New columns added.\n",
            "    SampleID  Water_pH  Turbidity_NTU  Chlorine_mg_L BacterialPresence  \\\n",
            "0          1      7.35           0.78           0.82                No   \n",
            "1          2      6.90           0.10           0.68               Yes   \n",
            "2          3      7.45           0.64           1.19               Yes   \n",
            "3          4      8.07           0.18           0.06                No   \n",
            "4          5      6.84           2.48           0.88                No   \n",
            "5          6      6.84           4.43           0.84               Yes   \n",
            "6          7      8.11           0.11           0.21                No   \n",
            "7          8      7.54           4.66           0.80                No   \n",
            "8          9      6.67           1.11           0.60                No   \n",
            "9         10      7.38           0.53           0.43               Yes   \n",
            "10        11      6.68           0.12           0.25               Yes   \n",
            "11        12      6.67           1.04           0.28                No   \n",
            "\n",
            "    EColi_MPN  Rainfall_mm  AvgTemperature_C OutbreakRisk  pH_deviation  \\\n",
            "0           0        18.44              30.3          Low          0.35   \n",
            "1           5        30.83              22.4         High          0.10   \n",
            "2           2        26.78              32.7         High          0.45   \n",
            "3           0        61.65              38.7          Low          1.07   \n",
            "4           2        49.33              24.5       Medium          0.16   \n",
            "5          10        52.01              21.3         High          0.16   \n",
            "6           2        24.55              27.1       Medium          1.11   \n",
            "7          50        22.07              26.7       Medium          0.54   \n",
            "8           1        41.52              31.3       Medium          0.33   \n",
            "9           0        65.23              29.2         High          0.38   \n",
            "10        100         9.83              26.5         High          0.32   \n",
            "11          1        31.70              28.5       Medium          0.33   \n",
            "\n",
            "    chlorine_deficient  turbidity_risky  turbidity_ecoli_interaction  \\\n",
            "0                    0                0                         0.00   \n",
            "1                    0                0                         0.50   \n",
            "2                    0                0                         1.28   \n",
            "3                    1                0                         0.00   \n",
            "4                    0                0                         4.96   \n",
            "5                    0                0                        44.30   \n",
            "6                    1                0                         0.22   \n",
            "7                    0                0                       233.00   \n",
            "8                    0                0                         1.11   \n",
            "9                    0                0                         0.00   \n",
            "10                   1                0                        12.00   \n",
            "11                   1                0                         1.04   \n",
            "\n",
            "   Rainfall_bin  \n",
            "0           Low  \n",
            "1        Medium  \n",
            "2        Medium  \n",
            "3          High  \n",
            "4          High  \n",
            "5          High  \n",
            "6        Medium  \n",
            "7           Low  \n",
            "8        Medium  \n",
            "9          High  \n",
            "10          Low  \n",
            "11       Medium  \n",
            "\n",
            "Target mapping applied. Value counts:\n",
            " OutbreakRisk\n",
            "1    995\n",
            "2    762\n",
            "0    243\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Train/test split completed. Train shape: (1600, 12) Test shape: (400, 12)\n",
            "Train class distribution:\n",
            " OutbreakRisk\n",
            "1    796\n",
            "2    610\n",
            "0    194\n",
            "Name: count, dtype: int64\n",
            "Test class distribution:\n",
            " OutbreakRisk\n",
            "1    199\n",
            "2    152\n",
            "0     49\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Processed training data sample:\n",
            "      Water_pH  Turbidity_NTU  Chlorine_mg_L  EColi_MPN  Rainfall_mm  \\\n",
            "1562 -2.555678      -0.103105       0.565823   1.790272    -0.095870   \n",
            "1573 -1.452736      -0.202899       0.021159  -0.831305    -0.918603   \n",
            "883   1.017855       2.458276       0.565823   1.790272     2.441694   \n",
            "1526  1.885503       0.296071       1.723234  -0.719748    -1.063882   \n",
            "1348 -1.467442      -0.934722       1.008363  -0.719748    -1.300490   \n",
            "122   1.385502       0.154696       0.293491   1.790272     1.909904   \n",
            "1247 -0.849794       0.204593      -0.761796   1.399824    -0.362535   \n",
            "905  -0.011558      -0.552178       1.723234   1.399824    -0.925539   \n",
            "1750 -2.680678      -0.427436      -1.068169   0.284260    -0.860029   \n",
            "1378 -0.673323       0.021638      -0.285215  -0.608192    -1.144421   \n",
            "435   0.017854       0.986314      -0.319256   0.284260     0.779272   \n",
            "973  -0.732147      -0.344274       0.259449  -0.831305     0.570024   \n",
            "\n",
            "      AvgTemperature_C  pH_deviation  turbidity_ecoli_interaction  \\\n",
            "1562          0.119576      2.708395                     1.984533   \n",
            "1573         -0.605964      1.015151                    -0.726812   \n",
            "883           0.381576      0.471335                     1.984533   \n",
            "1526          0.724192      1.929750                    -0.586646   \n",
            "1348         -1.069504      1.039870                    -0.707254   \n",
            "122          -0.424579      1.089307                     1.984533   \n",
            "1247         -0.726888      0.001676                     1.897235   \n",
            "905          -0.726888     -1.258987                     0.414078   \n",
            "1750         -0.807503      2.708395                    -0.034129   \n",
            "1378          0.361422     -0.294950                    -0.500264   \n",
            "435           0.220345     -1.209549                     1.351237   \n",
            "973           0.300961     -0.196075                    -0.726812   \n",
            "\n",
            "      BacterialPresence_bin  Rainfall_bin_High  Rainfall_bin_Low  \\\n",
            "1562                    1.0                0.0               0.0   \n",
            "1573                    0.0                0.0               1.0   \n",
            "883                     0.0                1.0               0.0   \n",
            "1526                    1.0                0.0               1.0   \n",
            "1348                    0.0                0.0               1.0   \n",
            "122                     0.0                1.0               0.0   \n",
            "1247                    0.0                0.0               0.0   \n",
            "905                     0.0                0.0               1.0   \n",
            "1750                    0.0                0.0               1.0   \n",
            "1378                    0.0                0.0               1.0   \n",
            "435                     0.0                1.0               0.0   \n",
            "973                     1.0                1.0               0.0   \n",
            "\n",
            "      Rainfall_bin_Medium  \n",
            "1562                  1.0  \n",
            "1573                  0.0  \n",
            "883                   0.0  \n",
            "1526                  0.0  \n",
            "1348                  0.0  \n",
            "122                   0.0  \n",
            "1247                  1.0  \n",
            "905                   0.0  \n",
            "1750                  0.0  \n",
            "1378                  0.0  \n",
            "435                   0.0  \n",
            "973                   0.0  \n",
            "imblearn not available or SMOTE failed. Skipping SMOTE. Error: No module named 'imblearn'\n",
            "\n",
            "Preprocessor pipeline saved to: model_artifacts/preprocessor_pipeline.joblib\n",
            "\n",
            "Final shapes:\n",
            "X_train: (1600, 12) y_train: (1600,)\n",
            "X_test: (400, 12) y_test: (400,)\n",
            "\n",
            "Processed feature names:\n",
            " ['Water_pH', 'Turbidity_NTU', 'Chlorine_mg_L', 'EColi_MPN', 'Rainfall_mm', 'AvgTemperature_C', 'pH_deviation', 'turbidity_ecoli_interaction', 'BacterialPresence_bin', 'Rainfall_bin_High', 'Rainfall_bin_Low', 'Rainfall_bin_Medium']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import joblib\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"iot_sensor_dataset.csv\")\n",
        "print(df.head(12))\n",
        "\n",
        "\n",
        "print(\"\\nDtypes:\\n\", df.dtypes)\n",
        "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
        "print(\"\\nOutbreakRisk distribution:\\n\", df['OutbreakRisk'].value_counts())\n",
        "print(\"\\nUnique values for EColi_MPN:\", sorted(df['EColi_MPN'].unique()))\n",
        "\n",
        "\n",
        "num_cols = [\"Water_pH\", \"Turbidity_NTU\", \"Chlorine_mg_L\",\n",
        "            \"EColi_MPN\", \"Rainfall_mm\", \"AvgTemperature_C\"]\n",
        "for c in num_cols:\n",
        "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
        "\n",
        "if 'SampleID' in df.columns:\n",
        "    dup_count = df['SampleID'].duplicated().sum()\n",
        "    if dup_count > 0:\n",
        "        print(f\"\\nFound {dup_count} duplicate SampleID rows. Dropping duplicates keeping first occurrence.\")\n",
        "        df = df.drop_duplicates(subset=['SampleID'])\n",
        "\n",
        "print(\"\\nMissing values after numeric coercion:\\n\", df.isnull().sum())\n",
        "\n",
        "\n",
        "df['pH_deviation'] = (df['Water_pH'] - 7.0).abs()\n",
        "df['chlorine_deficient'] = (df['Chlorine_mg_L'] < 0.3).astype(int)\n",
        "df['turbidity_risky'] = (df['Turbidity_NTU'] > 5.0).astype(int)\n",
        "df['turbidity_ecoli_interaction'] = df['Turbidity_NTU'] * df['EColi_MPN']\n",
        "df['Rainfall_bin'] = pd.qcut(df['Rainfall_mm'], q=3, labels=['Low', 'Medium', 'High'])\n",
        "\n",
        "print(\"\\nFeature engineering completed. New columns added.\")\n",
        "print(df.head(12))\n",
        "\n",
        "X = df.drop(columns=['SampleID', 'OutbreakRisk']) if 'SampleID' in df.columns else df.drop(columns=['OutbreakRisk'])\n",
        "y = df['OutbreakRisk'].copy()\n",
        "target_map = {'Low': 0, 'Medium': 1, 'High': 2}\n",
        "y_encoded = y.map(target_map)\n",
        "if y_encoded.isnull().any():\n",
        "    raise ValueError(\"Found unknown labels in OutbreakRisk not in {Low, Medium, High}\")\n",
        "print(\"\\nTarget mapping applied. Value counts:\\n\", y_encoded.value_counts())\n",
        "\n",
        "# --- Step 5: IQR capper transformer ---\n",
        "class IQRCapper(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, factor=1.5, columns=None):\n",
        "        self.factor = factor\n",
        "        self.columns = columns\n",
        "        self.bounds_ = {}\n",
        "    def fit(self, X, y=None):\n",
        "        X = pd.DataFrame(X, columns=self.columns)\n",
        "        for col in self.columns:\n",
        "            q1 = X[col].quantile(0.25)\n",
        "            q3 = X[col].quantile(0.75)\n",
        "            iqr = q3 - q1\n",
        "            lower = q1 - self.factor * iqr\n",
        "            upper = q3 + self.factor * iqr\n",
        "            self.bounds_[col] = (lower, upper)\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        X = pd.DataFrame(X, columns=self.columns).copy()\n",
        "        for col, (lower, upper) in self.bounds_.items():\n",
        "            X[col] = X[col].clip(lower=lower, upper=upper)\n",
        "        return X.values\n",
        "\n",
        "numeric_features = [\"Water_pH\", \"Turbidity_NTU\", \"Chlorine_mg_L\",\n",
        "                    \"EColi_MPN\", \"Rainfall_mm\", \"AvgTemperature_C\",\n",
        "                    \"pH_deviation\", \"turbidity_ecoli_interaction\"]\n",
        "\n",
        "# --- Step 6: Custom transformer for bacterial presence (no lambda!) ---\n",
        "def bacteria_to_binary(x):\n",
        "    return np.where(x == \"Yes\", 1, 0).reshape(-1, 1)\n",
        "\n",
        "# --- Step 7: Pipelines ---\n",
        "numeric_pipeline = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"iqr_capper\", IQRCapper(columns=numeric_features, factor=1.5)),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    (\"num\", numeric_pipeline, numeric_features),\n",
        "    (\"bacteria_bin\", FunctionTransformer(bacteria_to_binary), [\"BacterialPresence\"]),\n",
        "    (\"rainfall_ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False), [\"Rainfall_bin\"])\n",
        "], remainder='drop')\n",
        "\n",
        "# --- Step 8: Train/test split (stratified) ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42\n",
        ")\n",
        "print(\"\\nTrain/test split completed. Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
        "print(\"Train class distribution:\\n\", y_train.value_counts())\n",
        "print(\"Test class distribution:\\n\", y_test.value_counts())\n",
        "\n",
        "# --- Step 9: Fit & transform ---\n",
        "preprocessor.fit(X_train)\n",
        "X_train_proc = preprocessor.transform(X_train)\n",
        "X_test_proc = preprocessor.transform(X_test)\n",
        "\n",
        "rainfall_ohe_categories = preprocessor.named_transformers_['rainfall_ohe'].categories_[0].tolist()\n",
        "rainfall_ohe_colnames = [f\"Rainfall_bin_{cat}\" for cat in rainfall_ohe_categories]\n",
        "processed_colnames = numeric_features + [\"BacterialPresence_bin\"] + rainfall_ohe_colnames\n",
        "\n",
        "X_train_df = pd.DataFrame(X_train_proc, columns=processed_colnames, index=X_train.index)\n",
        "X_test_df = pd.DataFrame(X_test_proc, columns=processed_colnames, index=X_test.index)\n",
        "\n",
        "print(\"\\nProcessed training data sample:\")\n",
        "print(X_train_df.head(12))\n",
        "\n",
        "# --- Step 10: Optional SMOTE ---\n",
        "smote_applied = False\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "    counts = Counter(y_train)\n",
        "    maj = max(counts.values())\n",
        "    minc = min(counts.values())\n",
        "    if minc < 0.5 * maj:\n",
        "        print(\"Significant imbalance detected, applying SMOTE on training data...\")\n",
        "        sm = SMOTE(random_state=42)\n",
        "        X_train_res, y_train_res = sm.fit_resample(X_train_df, y_train.values)\n",
        "        smote_applied = True\n",
        "        print(\"After SMOTE:\", Counter(y_train_res))\n",
        "        X_train_df = pd.DataFrame(X_train_res, columns=processed_colnames)\n",
        "        y_train = pd.Series(y_train_res, name='OutbreakRisk')\n",
        "    else:\n",
        "        print(\"Imbalance not severe; skipping SMOTE.\")\n",
        "except Exception as e:\n",
        "    print(\"imblearn not available or SMOTE failed. Skipping SMOTE. Error:\", e)\n",
        "\n",
        "# --- Step 11: Save preprocessor ---\n",
        "os.makedirs(\"model_artifacts\", exist_ok=True)\n",
        "preprocessor_file = \"model_artifacts/preprocessor_pipeline.joblib\"\n",
        "joblib.dump(preprocessor, preprocessor_file)\n",
        "print(f\"\\nPreprocessor pipeline saved to: {preprocessor_file}\")\n",
        "\n",
        "print(\"\\nFinal shapes:\")\n",
        "print(\"X_train:\", X_train_df.shape, \"y_train:\", y_train.shape)\n",
        "print(\"X_test:\", X_test_df.shape, \"y_test:\", y_test.shape)\n",
        "print(\"\\nProcessed feature names:\\n\", processed_colnames)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "sk_version = sklearn.__version__\n",
        "print(sk_version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7Jw8zrydZQ3",
        "outputId": "e0ac3f59-5bb7-4f41-be97-63e6da93fc19"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import time\n",
        "import joblib\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# sklearn imports\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV\n",
        "from sklearn.pipeline import Pipeline as SKPipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier, StackingClassifier\n",
        "from sklearn.metrics import (accuracy_score, balanced_accuracy_score, f1_score,\n",
        "                             classification_report, confusion_matrix, recall_score)\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "# Optional libs\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE\n",
        "    from imblearn.pipeline import Pipeline as ImbPipeline\n",
        "    IMBLEARN_AVAILABLE = True\n",
        "except Exception:\n",
        "    IMBLEARN_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    import xgboost as xgb\n",
        "    XGBOOST_AVAILABLE = True\n",
        "except Exception:\n",
        "    XGBOOST_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    import shap\n",
        "    SHAP_AVAILABLE = True\n",
        "except Exception:\n",
        "    SHAP_AVAILABLE = False\n",
        "\n",
        "# ---------- Configuration ----------\n",
        "RANDOM_STATE = 42\n",
        "N_JOBS = -1\n",
        "ARTIFACT_DIR = \"model_artifacts\"\n",
        "CSV_PATH = \"iot_sensor_dataset.csv\"  # change if needed\n",
        "\n",
        "# ---------- Utility / Transformers (top-level classes only) ----------\n",
        "class IQRCapper(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Caps numeric columns at [Q1 - k*IQR, Q3 + k*IQR].\"\"\"\n",
        "    def __init__(self, factor=1.5, columns=None):\n",
        "        self.factor = factor\n",
        "        self.columns = columns  # store as given, no modification\n",
        "        self.bounds_ = {}\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        cols = self.columns\n",
        "        Xdf = pd.DataFrame(X, columns=cols)\n",
        "        self.bounds_ = {}\n",
        "        for col in cols:\n",
        "            q1 = Xdf[col].quantile(0.25)\n",
        "            q3 = Xdf[col].quantile(0.75)\n",
        "            iqr = q3 - q1\n",
        "            lower = q1 - self.factor * iqr\n",
        "            upper = q3 + self.factor * iqr\n",
        "            self.bounds_[col] = (lower, upper)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        cols = self.columns\n",
        "        Xdf = pd.DataFrame(X, columns=cols).copy()\n",
        "        for col, (lower, upper) in self.bounds_.items():\n",
        "            Xdf[col] = Xdf[col].clip(lower=lower, upper=upper)\n",
        "        return Xdf.values\n",
        "\n",
        "\n",
        "class BacteriaPresenceEncoder(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"Encodes BacterialPresence 'Yes'/'No' as 1/0 in a picklable transformer.\"\"\"\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    def transform(self, X):\n",
        "        # X may be DataFrame/array-like with shape (n_samples, 1)\n",
        "        arr = np.array(X).reshape(-1,)\n",
        "        return np.where(arr == \"Yes\", 1, 0).reshape(-1, 1)\n",
        "\n",
        "# ---------- Load data ----------\n",
        "if not os.path.exists(CSV_PATH):\n",
        "    raise FileNotFoundError(f\"CSV file not found at '{CSV_PATH}'. Put your iot_sensor_dataset.csv in the same folder or update CSV_PATH.\")\n",
        "\n",
        "df = pd.read_csv(CSV_PATH)\n",
        "print(\"Loaded CSV. shape:\", df.shape)\n",
        "print(df.head(8))\n",
        "\n",
        "# ---------- Basic EDA & preprocessing-ready steps ----------\n",
        "num_cols = [\"Water_pH\", \"Turbidity_NTU\", \"Chlorine_mg_L\", \"EColi_MPN\", \"Rainfall_mm\", \"AvgTemperature_C\"]\n",
        "for c in num_cols:\n",
        "    df[c] = pd.to_numeric(df[c], errors='coerce')\n",
        "\n",
        "# Feature engineering\n",
        "df['pH_deviation'] = (df['Water_pH'] - 7.0).abs()\n",
        "df['chlorine_deficient'] = (df['Chlorine_mg_L'] < 0.3).astype(int)\n",
        "df['turbidity_risky'] = (df['Turbidity_NTU'] > 5.0).astype(int)\n",
        "df['turbidity_ecoli_interaction'] = df['Turbidity_NTU'] * df['EColi_MPN']\n",
        "# Rainfall bins (3 quantile bins)\n",
        "df['Rainfall_bin'] = pd.qcut(df['Rainfall_mm'], q=3, labels=['Low', 'Medium', 'High'])\n",
        "\n",
        "# Target mapping\n",
        "target_map = {'Low': 0, 'Medium': 1, 'High': 2}\n",
        "if 'OutbreakRisk' not in df.columns:\n",
        "    raise KeyError(\"OutbreakRisk column not found in CSV.\")\n",
        "y = df['OutbreakRisk'].map(target_map)\n",
        "if y.isnull().any():\n",
        "    raise ValueError(\"Found unexpected labels in OutbreakRisk. Expect only 'Low','Medium','High'.\")\n",
        "\n",
        "# Features\n",
        "if 'SampleID' in df.columns:\n",
        "    X = df.drop(columns=['SampleID', 'OutbreakRisk'])\n",
        "else:\n",
        "    X = df.drop(columns=['OutbreakRisk'])\n",
        "\n",
        "print(\"\\nAfter feature engineering sample:\")\n",
        "print(X.head(6))\n",
        "\n",
        "# ---------- Preprocessor ----------\n",
        "numeric_features = [\"Water_pH\", \"Turbidity_NTU\", \"Chlorine_mg_L\",\n",
        "                    \"EColi_MPN\", \"Rainfall_mm\", \"AvgTemperature_C\",\n",
        "                    \"pH_deviation\", \"turbidity_ecoli_interaction\"]\n",
        "\n",
        "# numeric pipeline\n",
        "numeric_pipeline = SKPipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"iqr_capper\", IQRCapper(columns=numeric_features, factor=1.5)),\n",
        "    (\"scaler\", StandardScaler())\n",
        "])\n",
        "\n",
        "# OneHotEncoder compatibility\n",
        "from sklearn import __version__ as sklearn_version\n",
        "try:\n",
        "    # prefer sparse_output for modern sklearn\n",
        "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "except TypeError:\n",
        "    # fallback to older sklearn versions\n",
        "    ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
        "\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    (\"num\", numeric_pipeline, numeric_features),\n",
        "    (\"bacteria_bin\", BacteriaPresenceEncoder(), [\"BacterialPresence\"]),\n",
        "    (\"rainfall_ohe\", ohe, [\"Rainfall_bin\"])\n",
        "], remainder='drop')\n",
        "\n",
        "# ---------- Train/test split ----------\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
        "                                                    stratify=y, random_state=RANDOM_STATE)\n",
        "print(\"\\nTrain/test shapes:\", X_train.shape, X_test.shape)\n",
        "print(\"Train class distribution:\", Counter(y_train))\n",
        "\n",
        "# ---------- Fit preprocessor and create DataFrames of processed features (for inspection) ----------\n",
        "preprocessor.fit(X_train)\n",
        "X_train_proc = preprocessor.transform(X_train)\n",
        "X_test_proc = preprocessor.transform(X_test)\n",
        "\n",
        "# Build processed column names\n",
        "rainfall_categories = preprocessor.named_transformers_['rainfall_ohe'].categories_[0].tolist()\n",
        "rainfall_cols = [f\"Rainfall_bin_{c}\" for c in rainfall_categories]\n",
        "processed_colnames = numeric_features + [\"BacterialPresence_bin\"] + rainfall_cols\n",
        "\n",
        "X_train_df = pd.DataFrame(X_train_proc, columns=processed_colnames, index=X_train.index)\n",
        "X_test_df = pd.DataFrame(X_test_proc, columns=processed_colnames, index=X_test.index)\n",
        "\n",
        "print(\"\\nProcessed features sample:\")\n",
        "print(X_train_df.head(6))\n",
        "\n",
        "# ---------- Helper: Build pipeline (use SMOTE inside if available and requested) ----------\n",
        "def build_pipeline(clf, use_smote=False):\n",
        "    if IMBLEARN_AVAILABLE and use_smote:\n",
        "        return ImbPipeline(steps=[\n",
        "            (\"preproc\", preprocessor),\n",
        "            (\"smote\", SMOTE(random_state=RANDOM_STATE)),\n",
        "            (\"clf\", clf)\n",
        "        ])\n",
        "    else:\n",
        "        return SKPipeline(steps=[\n",
        "            (\"preproc\", preprocessor),\n",
        "            (\"clf\", clf)\n",
        "        ])\n",
        "\n",
        "# ---------- Candidate models & hyperparameter search specs ----------\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "models_to_search = {}\n",
        "\n",
        "# Logistic Regression (regularized)\n",
        "lr = LogisticRegression(solver='saga', class_weight='balanced', max_iter=5000, random_state=RANDOM_STATE, n_jobs=1)\n",
        "models_to_search['logistic'] = {\n",
        "    \"pipeline\": build_pipeline(lr, use_smote=False),\n",
        "    \"params\": {\n",
        "        \"clf__C\": [1e-3, 1e-2, 1e-1, 1, 10, 100],\n",
        "        \"clf__penalty\": [\"l2\"]\n",
        "    },\n",
        "    \"n_iter\": 8\n",
        "}\n",
        "\n",
        "# Random Forest\n",
        "rf = RandomForestClassifier(random_state=RANDOM_STATE, n_jobs=N_JOBS, class_weight='balanced')\n",
        "models_to_search['random_forest'] = {\n",
        "    \"pipeline\": build_pipeline(rf, use_smote=True if IMBLEARN_AVAILABLE else False),\n",
        "    \"params\": {\n",
        "        \"clf__n_estimators\": [100, 200, 400],\n",
        "        \"clf__max_depth\": [None, 8, 16, 24],\n",
        "        \"clf__min_samples_split\": [2, 5, 10],\n",
        "        \"clf__min_samples_leaf\": [1, 2, 4]\n",
        "    },\n",
        "    \"n_iter\": 20\n",
        "}\n",
        "\n",
        "\n",
        "hgb = HistGradientBoostingClassifier(random_state=RANDOM_STATE)\n",
        "models_to_search['hist_gb'] = {\n",
        "    \"pipeline\": build_pipeline(hgb, use_smote=False),\n",
        "    \"params\": {\n",
        "        \"clf__learning_rate\": [0.01, 0.05, 0.1],\n",
        "        \"clf__max_iter\": [100, 200, 400],\n",
        "        \"clf__max_depth\": [None, 5, 10],\n",
        "        \"clf__l2_regularization\": [0.0, 0.1, 1.0]\n",
        "    },\n",
        "    \"n_iter\": 18\n",
        "}\n",
        "\n",
        "\n",
        "if XGBOOST_AVAILABLE:\n",
        "    xgb_clf = xgb.XGBClassifier(objective='multi:softprob', eval_metric='mlogloss',\n",
        "                                use_label_encoder=False, n_jobs=N_JOBS, random_state=RANDOM_STATE)\n",
        "    models_to_search['xgboost'] = {\n",
        "        \"pipeline\": build_pipeline(xgb_clf, use_smote=False),\n",
        "        \"params\": {\n",
        "            \"clf__n_estimators\": [100, 200, 400],\n",
        "            \"clf__max_depth\": [3, 6, 10],\n",
        "            \"clf__learning_rate\": [0.01, 0.05, 0.1],\n",
        "            \"clf__subsample\": [0.6, 0.8, 1.0],\n",
        "            \"clf__colsample_bytree\": [0.6, 0.8, 1.0]\n",
        "        },\n",
        "        \"n_iter\": 25\n",
        "    }\n",
        "\n",
        "\n",
        "results = {}\n",
        "start_time = time.time()\n",
        "for name, spec in models_to_search.items():\n",
        "    print(f\"\\n--- Tuning {name} ---\")\n",
        "    pipeline = spec[\"pipeline\"]\n",
        "    param_dist = spec[\"params\"]\n",
        "    n_iter = spec.get(\"n_iter\", 20)\n",
        "    # If the param grid size < n_iter, sklearn will warn; it's okay - RandomizedSearchCV handles it.\n",
        "    search = RandomizedSearchCV(pipeline, param_distributions=param_dist,\n",
        "                                n_iter=n_iter, scoring='f1_macro', cv=cv,\n",
        "                                random_state=RANDOM_STATE, n_jobs=N_JOBS, verbose=1)\n",
        "    search.fit(X_train, y_train)\n",
        "    print(f\"Best CV {name} score (f1_macro): {search.best_score_:.4f}\")\n",
        "    print(\"Best params:\", search.best_params_)\n",
        "    results[name] = search\n",
        "elapsed = time.time() - start_time\n",
        "print(f\"\\nHyperparameter tuning finished in {elapsed/60:.2f} minutes\")\n",
        "\n",
        "\n",
        "def evaluate_model(model_pipeline, X_test, y_test, model_name=\"model\"):\n",
        "    y_pred = model_pipeline.predict(X_test)\n",
        "    try:\n",
        "        y_prob = model_pipeline.predict_proba(X_test)\n",
        "    except Exception:\n",
        "        y_prob = None\n",
        "    print(f\"\\n=== Evaluation: {model_name} ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Balanced accuracy:\", balanced_accuracy_score(y_test, y_pred))\n",
        "    print(\"Macro F1:\", f1_score(y_test, y_pred, average='macro'))\n",
        "    # recall per class; index 2 is 'High'\n",
        "    recs = recall_score(y_test, y_pred, average=None)\n",
        "    rec_high = recs[2] if len(recs) > 2 else None\n",
        "    print(\"Recall for High class (label=2):\", rec_high)\n",
        "    print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, digits=4))\n",
        "    print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "    return {\"y_pred\": y_pred, \"y_prob\": y_prob}\n",
        "\n",
        "\n",
        "eval_summary = {}\n",
        "for name, search in results.items():\n",
        "    best_pipe = search.best_estimator_\n",
        "    eval_summary[name] = evaluate_model(best_pipe, X_test, y_test, model_name=name)\n",
        "\n",
        "best_name = None\n",
        "best_f1 = -1\n",
        "for name, out in eval_summary.items():\n",
        "    f1 = f1_score(y_test, out[\"y_pred\"], average='macro')\n",
        "    if f1 > best_f1:\n",
        "        best_f1 = f1\n",
        "        best_name = name\n",
        "print(f\"\\nSelected best model: {best_name} with test macro-F1 = {best_f1:.4f}\")\n",
        "\n",
        "best_search = results[best_name]\n",
        "best_model_pipeline = best_search.best_estimator_\n",
        "\n",
        "# ---------- Calibrate probabilities (useful in real-world risk scoring) ----------\n",
        "print(\"\\nCalibrating best model probabilities (CalibratedClassifierCV, method='sigmoid') ...\")\n",
        "calibrator = CalibratedClassifierCV(best_model_pipeline, cv=5, method='sigmoid')\n",
        "calibrator.fit(X_train, y_train)\n",
        "print(\"Calibration complete.\")\n",
        "\n",
        "# ---------- Save artifacts (preprocessor, best model, calibrated) ----------\n",
        "os.makedirs(ARTIFACT_DIR, exist_ok=True)\n",
        "preprocessor_path = os.path.join(ARTIFACT_DIR, \"preprocessor.joblib\")\n",
        "best_model_path = os.path.join(ARTIFACT_DIR, f\"best_model_{best_name}.joblib\")\n",
        "calibrator_path = os.path.join(ARTIFACT_DIR, f\"calibrated_{best_name}.joblib\")\n",
        "\n",
        "joblib.dump(preprocessor, preprocessor_path)\n",
        "joblib.dump(best_model_pipeline, best_model_path)\n",
        "joblib.dump(calibrator, calibrator_path)\n",
        "print(\"\\nSaved preprocessor, best model pipeline, and calibrated model to:\", ARTIFACT_DIR)\n",
        "\n",
        "# ---------- SHAP explainability (if available and model supports) ----------\n",
        "if SHAP_AVAILABLE:\n",
        "    try:\n",
        "        print(\"\\nComputing SHAP importances (this may take a bit)...\")\n",
        "        # Use a subset for speed & to avoid rendering in headless env\n",
        "        X_sample = X_test.sample(n=min(200, len(X_test)), random_state=RANDOM_STATE)\n",
        "        # Transform to model input\n",
        "        X_sample_trans = best_model_pipeline.named_steps['preproc'].transform(X_sample) \\\n",
        "                         if hasattr(best_model_pipeline, 'named_steps') else preprocessor.transform(X_sample)\n",
        "        clf = best_model_pipeline.named_steps['clf'] if hasattr(best_model_pipeline, 'named_steps') else best_model_pipeline\n",
        "        # Use TreeExplainer for tree models, otherwise use a model-agnostic Explainer\n",
        "        if ('XGB' in str(type(clf))) or ('RandomForest' in str(type(clf))) or ('HistGradientBoosting' in str(type(clf))):\n",
        "            expl = shap.Explainer(clf)\n",
        "            shap_vals = expl(X_sample_trans)\n",
        "            # Save mean absolute SHAP per feature (safe alternative to plotting)\n",
        "            mean_abs_shap = np.abs(shap_vals.values).mean(axis=0)\n",
        "            feat_names = processed_colnames\n",
        "            shap_imp_df = pd.DataFrame({\"feature\": feat_names, \"mean_abs_shap\": mean_abs_shap})\n",
        "            shap_imp_df = shap_imp_df.sort_values(\"mean_abs_shap\", ascending=False)\n",
        "            shap_imp_df.to_csv(os.path.join(ARTIFACT_DIR, \"shap_feature_importance.csv\"), index=False)\n",
        "            print(\"Saved SHAP feature importance csv to model_artifacts/shap_feature_importance.csv\")\n",
        "        else:\n",
        "            # fallback: use shap.Explainer model-agnostic (may be slower)\n",
        "            expl = shap.Explainer(best_model_pipeline.predict_proba, X_sample_trans)\n",
        "            shap_vals = expl(X_sample_trans)\n",
        "            mean_abs_shap = np.abs(shap_vals.values).mean(axis=0)\n",
        "            feat_names = processed_colnames\n",
        "            shap_imp_df = pd.DataFrame({\"feature\": feat_names, \"mean_abs_shap\": mean_abs_shap})\n",
        "            shap_imp_df = shap_imp_df.sort_values(\"mean_abs_shap\", ascending=False)\n",
        "            shap_imp_df.to_csv(os.path.join(ARTIFACT_DIR, \"shap_feature_importance.csv\"), index=False)\n",
        "            print(\"Saved model-agnostic SHAP importance to csv.\")\n",
        "    except Exception as e:\n",
        "        print(\"SHAP step failed (non-fatal):\", e)\n",
        "else:\n",
        "    print(\"\\nSHAP not installed. To enable explainability, install shap (`pip install shap`) and re-run.\")\n",
        "\n",
        "# ---------- Optional stacking ensemble (safe saving with fallback) ----------\n",
        "try:\n",
        "    print(\"\\nBuilding stacking ensemble from top tuned pipelines (if at least 2 models tuned)...\")\n",
        "    # sort by CV best_score_ to pick top 3\n",
        "    ranked = sorted(results.items(), key=lambda kv: kv[1].best_score_, reverse=True)\n",
        "    top = ranked[:3]\n",
        "    if len(top) >= 2:\n",
        "        estimators = []\n",
        "        for name, search in top:\n",
        "            estimators.append((name, search.best_estimator_))\n",
        "        # final estimator simple logistic regression\n",
        "        stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(max_iter=2000),\n",
        "                                   cv=cv, n_jobs=N_JOBS, passthrough=False)\n",
        "        stack.fit(X_train, y_train)\n",
        "        evaluate_model(stack, X_test, y_test, model_name=\"stacked_ensemble\")\n",
        "        # Try saving; if pickling fails, save components separately\n",
        "        stack_path = os.path.join(ARTIFACT_DIR, \"stacked_ensemble.joblib\")\n",
        "        try:\n",
        "            joblib.dump(stack, stack_path)\n",
        "            print(\"Saved stacking classifier to\", stack_path)\n",
        "        except Exception as e_save:\n",
        "            print(\"Failed to pickle stacking classifier directly:\", e_save)\n",
        "            # fallback: save individual estimators and final_estimator separately\n",
        "            fallback_dir = os.path.join(ARTIFACT_DIR, \"stacking_fallback\")\n",
        "            os.makedirs(fallback_dir, exist_ok=True)\n",
        "            joblib.dump(stack.named_estimators_, os.path.join(fallback_dir, \"named_estimators.joblib\"))\n",
        "            joblib.dump(stack.final_estimator_, os.path.join(fallback_dir, \"final_estimator.joblib\"))\n",
        "            print(\"Saved stacking components separately to\", fallback_dir)\n",
        "    else:\n",
        "        print(\"Not enough tuned models to build a stacking ensemble.\")\n",
        "except Exception as e:\n",
        "    print(\"Stacking step failed (non-fatal):\", e)\n",
        "\n",
        "print(\"\\nAll done. Check the\", ARTIFACT_DIR, \"folder for saved models and artifacts.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwgqIm-heyBC",
        "outputId": "faef87d8-14ac-4e93-f89d-35567bc70f7e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded CSV. shape: (2000, 9)\n",
            "   SampleID  Water_pH  Turbidity_NTU  Chlorine_mg_L BacterialPresence  \\\n",
            "0         1      7.35           0.78           0.82                No   \n",
            "1         2      6.90           0.10           0.68               Yes   \n",
            "2         3      7.45           0.64           1.19               Yes   \n",
            "3         4      8.07           0.18           0.06                No   \n",
            "4         5      6.84           2.48           0.88                No   \n",
            "5         6      6.84           4.43           0.84               Yes   \n",
            "6         7      8.11           0.11           0.21                No   \n",
            "7         8      7.54           4.66           0.80                No   \n",
            "\n",
            "   EColi_MPN  Rainfall_mm  AvgTemperature_C OutbreakRisk  \n",
            "0          0        18.44              30.3          Low  \n",
            "1          5        30.83              22.4         High  \n",
            "2          2        26.78              32.7         High  \n",
            "3          0        61.65              38.7          Low  \n",
            "4          2        49.33              24.5       Medium  \n",
            "5         10        52.01              21.3         High  \n",
            "6          2        24.55              27.1       Medium  \n",
            "7         50        22.07              26.7       Medium  \n",
            "\n",
            "After feature engineering sample:\n",
            "   Water_pH  Turbidity_NTU  Chlorine_mg_L BacterialPresence  EColi_MPN  \\\n",
            "0      7.35           0.78           0.82                No          0   \n",
            "1      6.90           0.10           0.68               Yes          5   \n",
            "2      7.45           0.64           1.19               Yes          2   \n",
            "3      8.07           0.18           0.06                No          0   \n",
            "4      6.84           2.48           0.88                No          2   \n",
            "5      6.84           4.43           0.84               Yes         10   \n",
            "\n",
            "   Rainfall_mm  AvgTemperature_C  pH_deviation  chlorine_deficient  \\\n",
            "0        18.44              30.3          0.35                   0   \n",
            "1        30.83              22.4          0.10                   0   \n",
            "2        26.78              32.7          0.45                   0   \n",
            "3        61.65              38.7          1.07                   1   \n",
            "4        49.33              24.5          0.16                   0   \n",
            "5        52.01              21.3          0.16                   0   \n",
            "\n",
            "   turbidity_risky  turbidity_ecoli_interaction Rainfall_bin  \n",
            "0                0                         0.00          Low  \n",
            "1                0                         0.50       Medium  \n",
            "2                0                         1.28       Medium  \n",
            "3                0                         0.00         High  \n",
            "4                0                         4.96         High  \n",
            "5                0                        44.30         High  \n",
            "\n",
            "Train/test shapes: (1600, 12) (400, 12)\n",
            "Train class distribution: Counter({1: 796, 2: 610, 0: 194})\n",
            "\n",
            "Processed features sample:\n",
            "      Water_pH  Turbidity_NTU  Chlorine_mg_L  EColi_MPN  Rainfall_mm  \\\n",
            "1562 -2.555678      -0.103105       0.565823   1.790272    -0.095870   \n",
            "1573 -1.452736      -0.202899       0.021159  -0.831305    -0.918603   \n",
            "883   1.017855       2.458276       0.565823   1.790272     2.441694   \n",
            "1526  1.885503       0.296071       1.723234  -0.719748    -1.063882   \n",
            "1348 -1.467442      -0.934722       1.008363  -0.719748    -1.300490   \n",
            "122   1.385502       0.154696       0.293491   1.790272     1.909904   \n",
            "\n",
            "      AvgTemperature_C  pH_deviation  turbidity_ecoli_interaction  \\\n",
            "1562          0.119576      2.708395                     1.984533   \n",
            "1573         -0.605964      1.015151                    -0.726812   \n",
            "883           0.381576      0.471335                     1.984533   \n",
            "1526          0.724192      1.929750                    -0.586646   \n",
            "1348         -1.069504      1.039870                    -0.707254   \n",
            "122          -0.424579      1.089307                     1.984533   \n",
            "\n",
            "      BacterialPresence_bin  Rainfall_bin_High  Rainfall_bin_Low  \\\n",
            "1562                    1.0                0.0               0.0   \n",
            "1573                    0.0                0.0               1.0   \n",
            "883                     0.0                1.0               0.0   \n",
            "1526                    1.0                0.0               1.0   \n",
            "1348                    0.0                0.0               1.0   \n",
            "122                     0.0                1.0               0.0   \n",
            "\n",
            "      Rainfall_bin_Medium  \n",
            "1562                  1.0  \n",
            "1573                  0.0  \n",
            "883                   0.0  \n",
            "1526                  0.0  \n",
            "1348                  0.0  \n",
            "122                   0.0  \n",
            "\n",
            "--- Tuning logistic ---\n",
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/model_selection/_search.py:317: UserWarning: The total space of parameters 6 is smaller than n_iter=8. Running 6 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best CV logistic score (f1_macro): 0.9311\n",
            "Best params: {'clf__penalty': 'l2', 'clf__C': 100}\n",
            "\n",
            "--- Tuning random_forest ---\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "Best CV random_forest score (f1_macro): 0.9598\n",
            "Best params: {'clf__n_estimators': 100, 'clf__min_samples_split': 2, 'clf__min_samples_leaf': 1, 'clf__max_depth': 24}\n",
            "\n",
            "--- Tuning hist_gb ---\n",
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "Best CV hist_gb score (f1_macro): 0.9680\n",
            "Best params: {'clf__max_iter': 100, 'clf__max_depth': 5, 'clf__learning_rate': 0.05, 'clf__l2_regularization': 0.0}\n",
            "\n",
            "Hyperparameter tuning finished in 0.70 minutes\n",
            "\n",
            "=== Evaluation: logistic ===\n",
            "Accuracy: 0.9275\n",
            "Balanced accuracy: 0.9493520232742662\n",
            "Macro F1: 0.9182259182259184\n",
            "Recall for High class (label=2): 0.9736842105263158\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7903    1.0000    0.8829        49\n",
            "           1     0.9775    0.8744    0.9231       199\n",
            "           2     0.9250    0.9737    0.9487       152\n",
            "\n",
            "    accuracy                         0.9275       400\n",
            "   macro avg     0.8976    0.9494    0.9182       400\n",
            "weighted avg     0.9346    0.9275    0.9279       400\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 49   0   0]\n",
            " [ 13 174  12]\n",
            " [  0   4 148]]\n",
            "\n",
            "=== Evaluation: random_forest ===\n",
            "Accuracy: 0.945\n",
            "Balanced accuracy: 0.950304017401724\n",
            "Macro F1: 0.9483603697889412\n",
            "Recall for High class (label=2): 0.9671052631578947\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9592    0.9592    0.9592        49\n",
            "           1     0.9634    0.9246    0.9436       199\n",
            "           2     0.9187    0.9671    0.9423       152\n",
            "\n",
            "    accuracy                         0.9450       400\n",
            "   macro avg     0.9471    0.9503    0.9484       400\n",
            "weighted avg     0.9459    0.9450    0.9450       400\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 47   2   0]\n",
            " [  2 184  13]\n",
            " [  0   5 147]]\n",
            "\n",
            "=== Evaluation: hist_gb ===\n",
            "Accuracy: 0.955\n",
            "Balanced accuracy: 0.9672595433306886\n",
            "Macro F1: 0.9607444168734491\n",
            "Recall for High class (label=2): 0.9671052631578947\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9608    1.0000    0.9800        49\n",
            "           1     0.9738    0.9347    0.9538       199\n",
            "           2     0.9304    0.9671    0.9484       152\n",
            "\n",
            "    accuracy                         0.9550       400\n",
            "   macro avg     0.9550    0.9673    0.9607       400\n",
            "weighted avg     0.9557    0.9550    0.9550       400\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 49   0   0]\n",
            " [  2 186  11]\n",
            " [  0   5 147]]\n",
            "\n",
            "Selected best model: hist_gb with test macro-F1 = 0.9607\n",
            "\n",
            "Calibrating best model probabilities (CalibratedClassifierCV, method='sigmoid') ...\n",
            "Calibration complete.\n",
            "\n",
            "Saved preprocessor, best model pipeline, and calibrated model to: model_artifacts\n",
            "\n",
            "SHAP not installed. To enable explainability, install shap (`pip install shap`) and re-run.\n",
            "\n",
            "Building stacking ensemble from top tuned pipelines (if at least 2 models tuned)...\n",
            "\n",
            "=== Evaluation: stacked_ensemble ===\n",
            "Accuracy: 0.9575\n",
            "Balanced accuracy: 0.9694525257868288\n",
            "Macro F1: 0.9626888964200399\n",
            "Recall for High class (label=2): 0.9736842105263158\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9608    1.0000    0.9800        49\n",
            "           1     0.9789    0.9347    0.9563       199\n",
            "           2     0.9308    0.9737    0.9518       152\n",
            "\n",
            "    accuracy                         0.9575       400\n",
            "   macro avg     0.9568    0.9695    0.9627       400\n",
            "weighted avg     0.9584    0.9575    0.9575       400\n",
            "\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 49   0   0]\n",
            " [  2 186  11]\n",
            " [  0   4 148]]\n",
            "Saved stacking classifier to model_artifacts/stacked_ensemble.joblib\n",
            "\n",
            "All done. Check the model_artifacts folder for saved models and artifacts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import joblib\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import HistGradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        # Add engineered features\n",
        "        X[\"pH_deviation\"] = (X[\"Water_pH\"] - 7.0).abs()\n",
        "        X[\"turbidity_ecoli_interaction\"] = X[\"Turbidity_NTU\"] * np.log1p(X[\"EColi_MPN\"])\n",
        "        X[\"Rainfall_bin\"] = pd.cut(\n",
        "            X[\"Rainfall_mm\"],\n",
        "            bins=[-np.inf, 20, 50, 100, np.inf],\n",
        "            labels=[\"Low\", \"Moderate\", \"High\", \"Extreme\"]\n",
        "        )\n",
        "        return X\n",
        "\n",
        "\n",
        "numeric_features = [\n",
        "    \"Water_pH\", \"Turbidity_NTU\", \"Chlorine_mg_L\",\n",
        "    \"EColi_MPN\", \"Rainfall_mm\", \"AvgTemperature_C\",\n",
        "    \"pH_deviation\", \"turbidity_ecoli_interaction\"\n",
        "]\n",
        "categorical_features = [\"BacterialPresence\", \"Rainfall_bin\"]\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numeric_features),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "final_pipeline = Pipeline(steps=[\n",
        "    (\"features\", FeatureEngineer()),\n",
        "    (\"preprocess\", preprocessor),\n",
        "    (\"model\", HistGradientBoostingClassifier(random_state=42))\n",
        "])\n",
        "\n",
        "X = df.drop(columns=[\"OutbreakRisk\"])\n",
        "y = df[\"OutbreakRisk\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "final_pipeline.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred = final_pipeline.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "\n",
        "joblib.dump(final_pipeline, \"model_artifacts/final_pipeline.joblib\")\n",
        "print(\" Final pipeline saved as model_artifacts/final_pipeline.joblib\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSkoxWrE-Fw4",
        "outputId": "2ed82cfa-0ed7-4010-dd74-f63567f6839d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9975\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        High       1.00      0.99      1.00       152\n",
            "         Low       1.00      1.00      1.00        49\n",
            "      Medium       0.99      1.00      1.00       199\n",
            "\n",
            "    accuracy                           1.00       400\n",
            "   macro avg       1.00      1.00      1.00       400\n",
            "weighted avg       1.00      1.00      1.00       400\n",
            "\n",
            " Final pipeline saved as model_artifacts/final_pipeline.joblib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "\n",
        "pipeline = joblib.load(\"model_artifacts/final_pipeline.joblib\")\n",
        "\n",
        "sample = pd.DataFrame([{\n",
        "    \"Water_pH\": 6.5,\n",
        "    \"Turbidity_NTU\": 4.0,\n",
        "    \"Chlorine_mg_L\": 0.3,\n",
        "    \"EColi_MPN\": 40,\n",
        "    \"Rainfall_mm\": 55.0,\n",
        "    \"AvgTemperature_C\": 30,\n",
        "    \"BacterialPresence\": \"No\"\n",
        "}])\n",
        "\n",
        "\n",
        "pred_class = pipeline.predict(sample)[0]\n",
        "pred_prob = pipeline.predict_proba(sample)[0]\n",
        "\n",
        "print(\"Predicted class:\", pred_class)\n",
        "print(\"Probabilities (Low, Medium, High):\", pred_prob)\n"
      ],
      "metadata": {
        "id": "8aq2su5cyWDO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfaf7101-2e33-4588-da83-ed45b2d8b345"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: Medium\n",
            "Probabilities (Low, Medium, High): [1.29775353e-07 2.28451944e-08 9.99999847e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uK3Cei9Z86NA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}